{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f519654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9849d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13, 14, 15],\n",
      "        [19, 20, 21]])\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([\n",
    "    [10, 11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20, 21]\n",
    "])\n",
    "\n",
    "context_size = 3\n",
    "\n",
    "idx_cond = idx[:, -context_size:]\n",
    "\n",
    "print(idx_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f818a9",
   "metadata": {},
   "source": [
    "‚∏ª\n",
    "\n",
    "\n",
    "# üêç Python Iteration Cheatsheet\n",
    "\n",
    "## üîÅ enumerate()\n",
    "\n",
    "Use enumerate() when you want both the index and the value:\n",
    "\n",
    "```python\n",
    "items = ['apple', 'banana', 'cherry']\n",
    "\n",
    "for i, item in enumerate(items):\n",
    "    print(i, item)\n",
    "\n",
    "Output:\n",
    "\n",
    "0 apple\n",
    "1 banana\n",
    "2 cherry\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîó zip()\n",
    "\n",
    "Use zip() to iterate over multiple lists in parallel:\n",
    "\n",
    "names = ['Alice', 'Bob', 'Charlie']\n",
    "scores = [85, 90, 95]\n",
    "\n",
    "for name, score in zip(names, scores):\n",
    "    print(name, score)\n",
    "\n",
    "Output:\n",
    "\n",
    "Alice 85\n",
    "Bob 90\n",
    "Charlie 95\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üéØ range()\n",
    "\n",
    "Use range() to create a sequence of numbers:\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "for i in range(1, 10, 2):  # start=1, stop=10, step=2\n",
    "    print(i)\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üßº map()\n",
    "\n",
    "Apply a function to every item in an iterable:\n",
    "\n",
    "nums = [1, 2, 3]\n",
    "squared = list(map(lambda x: x**2, nums))\n",
    "print(squared)  # [1, 4, 9]\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üßÉ filter()\n",
    "\n",
    "Filter items using a condition:\n",
    "\n",
    "nums = [1, 2, 3, 4, 5]\n",
    "evens = list(filter(lambda x: x % 2 == 0, nums))\n",
    "print(evens)  # [2, 4]\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üìå Quick Reference Table\n",
    "\n",
    "Function\tUse Case\n",
    "enumerate()\tGet index and value while iterating\n",
    "zip()\tIterate multiple sequences together\n",
    "range()\tGenerate a sequence of numbers\n",
    "map()\tApply function to all elements\n",
    "filter()\tSelect items that meet a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7b24c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb314691",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Taha/OneDrive/Desktop/LLM/Book/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    " text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6253c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b853779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        super().__init__()\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        length = len(token_ids)\n",
    "\n",
    "        for i in range(0, length - max_length - 1, stride ):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + 1 + max_length]\n",
    "\n",
    "            if len(input_chunk) == max_length and len(target_chunk) == max_length:\n",
    "                self.input_ids.append(torch.tensor(input_chunk))\n",
    "                self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.input_ids)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "            return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5642ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(\n",
    "        txt:str, \n",
    "        batch_size:int, \n",
    "        max_length:int, \n",
    "        stride: int, \n",
    "        shuffle: bool, \n",
    "        drop_last: bool, \n",
    "        num_workers: int\n",
    "):\n",
    "    \n",
    "\n",
    "    dataset = GPTDataset(\n",
    "        txt=txt,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69d4f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data, \n",
    "    batch_size=2, \n",
    "    max_length=256, \n",
    "    stride=256, \n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=256,\n",
    "    stride=256,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "593f1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c5b28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_batch(\n",
    "            train_loader, model, device, num_batch = eval_iter\n",
    "        )\n",
    "        \n",
    "        val_loss = calc_loss_batch(\n",
    "            val_loader, model, device, num_batch = eval_iter\n",
    "        )\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # allowed_special makes sure special tokens are handled correctly \n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # unsqueeze to add batch dimension  \n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Convert to 1D tensor and remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist()) # Convert to list for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens=50, context_size=context_size):\n",
    "     for _ in range(max_new_tokens):\n",
    "          idx_cond = idx[:, -context_size:]\n",
    "          with torch.no_grad():\n",
    "               logits = model(idx_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c81dce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_Sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model, idx = encoded, \n",
    "            max_new_tokens=50, context_size=context_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc9710b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, \n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, val_losses, track_token_seen = [], [], []\n",
    "    token_seen, general_mode = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss= calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if general_mode % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                      )\n",
    "                generate_and_print_Sample(\n",
    "                    model, tokenizer, device, start_context\n",
    "                    )\n",
    "                \n",
    "    return train_losses, val_losses, track_token_seen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
